Start 5 EC2 workers and run:
  1. (freedom, 0) on the 2005 dataset with combiner off
  	Total time taken (sum of first and second job) 
		11min10s+31s=11min41s=701s
	The number of mappers and reducers used for each job  
		Job1 : 210mappers, 32 reducers
		Job2 : 32 mappers, 1 reducers
	The size of the input (S3N_BYTES_READ)
		13,988,473,232 Bytes=13.028GB

  2.(freedom, 0) on the 2005 dataset with combiner on
	Total time taken (sum of first and second job) 
		6min10s+32s=6min42s=402s
	The number of mappers and reducers used for each job
		Job1 : 210mappers, 32 reducers
		Job2 : 32 mappers, 1 reducers
	The size of the input (S3N_BYTES_READ)
		13,988,471,626 Bytes=13.028GB

  3.(capital, 0) on the 2006 dataset with combiner on
	Total time taken (sum of first and second job)
		15min15s+30s=15min45s=945s
	The number of mappers and reducers used for each job
		Job1 : 216mappers, 32 reducers
		Job2 : 32 mappers, 1 reducers	
	The size of the input (S3N_BYTES_READ)
		19,139,788,414 Bytes=17.825GB
	The top 20 results (co-occurrence value and word) for each run (see below on how to view). Please save this in a file called <targetWord>-<funcNum>.txt. For example, the output of (capital, 0) should be saved in capital-0.txt

Terminate the 5 EC2 workers, then start 9 EC2 workers and run:
  4.(capital, 0) on the 2006 dataset with combiner on
	Total time taken (sum of first and second job)
		8min56sec+27sec=9min23sec=563s
	The number of mappers and reducers used for each job
		Job1 : 316mappers, 32 reducers
		Job2 : 32 mappers, 1 reducers
	The size of the input (S3N_BYTES_READ)
		19,139,833,534 Bytes=17.825GB
	The top 20 results (co-occurrence value and word) for each run (see below on how to view). Please save this in a file called <targetWord>-<funcNum>.txt. For example, the output of (capital, 0) should be saved in capital-0.txt

  5.(landmark, 1) on the 2006 dataset with combiner on
	Total time taken (sum of first and second job)
		8min42s+26s=9min8s=548s
	The number of mappers and reducers used for each job
		Job1 : 316mappers, 32 reducers
		Job2 : 32 mappers, 1 reducers
	The size of the input (S3N_BYTES_READ)
		19,139,801,465	Bytes=17.825GB
	The top 20 results (co-occurrence value and word) for each run (see below on how to view). Please save this in a file called <targetWord>-<funcNum>.txt. For example, the output of (capital, 0) should be saved in capital-0.txt

  6.(monument, 2) on the 2006 dataset with combiner on
	Total time taken (sum of first and second job)
		8min41s+28s=9min9s
	The number of mappers and reducers used for each job
		Job1 : 316mappers, 32 reducers
		Job2 : 32 mappers, 1 reducers
	The size of the input (S3N_BYTES_READ)
		19,139,807,529 Bytes=17.825GB
	The top 20 results (co-occurrence value and word) for each run (see below on how to view). Please save this in a file called <targetWord>-<funcNum>.txt. For example, the output of (capital, 0) should be saved in capital-0.txt



For the final submission, answer the following questions in a file named ec2experience.txt:

1. How long did each of the six runs take? How many mappers and how many reducers did you use?
   	It's in the record above.

2. For the two runs with (freedom, 0), how much faster did your code run on the 5 workers with the combiner turned on than with the combiner turned off? Express your answer as a percentage.
	701/402-1=74.4% faster

3. For the runs on the 2006 dataset, what was the median processing rate per GB (= 2^30 bytes) of input for the tests using 5 workers? Using 9 workers?
	For 5 workers, the processing rate is 0.0186GB/s, 0.0324GB/s,0.0189GB/s; so the median processing rate is 	  0.0189GB/s.
	For 9 workers, the processing rate is 0.0317GB/s, 0.03253s/GB, 0.0325GB/s; so the median processing rate is 0.0325GB/s. 
	
4. What was the percent speedup of running (capital, 0) with 9 workers over 5 workers? What is the maximum possible speedup, assuming your code is fully parallelizable? How well, in your opinion, does Hadoop parallelize your code? Justify your answer in 1-2 sentences.
	For (capital,0), the percent speedup is 67.9%.The maximal possible speedup is 9/5-1=80%. Hadoop parallelize my code pretty well because  the actual speedup is 85% of the maximal possible speedup.

5. For a single run on the 2006 dataset, what was the price per GB processed on with 5 workers? With 9 workers? (Recall that an extra-large instance costs $0.58 per hour, rounded up to the nearest hour.)
	With 5 workers, 5*0.58/17.825=$0.163/GB
	With 9 workers, 9*0.58/17.825=$0.293/GB

6. How much total money did you use to complete this project?
	5*0.58+9*0.58=$8.12